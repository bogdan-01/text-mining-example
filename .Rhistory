library(tidyverse)
library(janeaustenr)
library(tidytext)
# assign books to variable name
pride_prejudice <- prideprejudice
sense_sensibility <- sensesensibility
pride_prejudice_text <- tibble(
phrase = pride_prejudice,
id     = 1:length(pride_prejudice)
)
head(pride_prejudice_text)
words_pride_and_prejudice <-
pride_prejudice_text %>%
unnest_tokens(word, phrase)
words_pride_and_prejudice
# most common words in pride and prejudice are below, arranged in descending order from the most common to the least common.
words_pride_and_prejudice %>%
group_by(word) %>%
summarise(
count = n()
) %>%
arrange(desc(count))
sense_sensibility_text <- tibble(
phrase = sense_sensibility,
id     = 1:length(sense_sensibility)
)
head(sense_sensibility_text)
words_sense_sensibility <-
sense_sensibility_text %>%
unnest_tokens(word, phrase)
words_sense_sensibility
# most common words in pride and prejudice are below, arranged in descending order from the most common to the least common.
words_sense_sensibility %>%
group_by(word) %>%
summarise(
count = n()
) %>%
arrange(desc(count))
# I am doing an anti-join between the stop_words df found in the tidytext package and the book I am analysing. This will keep only the words which are not stop words.
words_pride_and_prejudice %>%
anti_join(stop_words) %>%
count(word, sort = TRUE)
words_sense_sensibility %>%
anti_join(stop_words) %>%
count(word, sort = TRUE)
# this shows a left join between the sentiment words from the 'bing' lexicon and the words found in the book. Notice not all words have a sentiment attached to them, these appear as NA.
words_pride_and_prejudice %>%
left_join(get_sentiments("bing"))
# now I want to keep just those words which have a sentiment, so I did an inner join.
words_pride_and_prejudice %>%
inner_join(get_sentiments("bing"))
# Now I want to sort them and find the most common sentiment words
# creating data frame with all sentiment words
sentiment_words_p_and_p <-
words_pride_and_prejudice %>%
inner_join(get_sentiments("bing"))
# filter for the most common positive words
sentiment_words_p_and_p %>%
filter(sentiment == "positive") %>%
count(word, sort = TRUE)
# filter for the most common negative words
sentiment_words_p_and_p %>%
filter(sentiment == "negative") %>%
count(word, sort = TRUE)
# this shows a left join between the sentiment words from the 'bing' lexicon and the words found in the book. Notice not all words have a sentiment attached to them, these appear as NA.
words_sense_sensibility %>%
left_join(get_sentiments("bing"))
# now I want to keep just those words which have a sentiment, so I did an inner join.
words_sense_sensibility %>%
inner_join(get_sentiments("bing"))
# Now I want to sort them and find the most common sentiment words
# creating data frame with all sentiment words
sentiment_words_s_and_s <-
words_sense_sensibility %>%
inner_join(get_sentiments("bing"))
# filter for the most common positive words
sentiment_words_s_and_s %>%
filter(sentiment == "positive") %>%
count(word, sort = TRUE)
# filter for the most common negative words
sentiment_words_s_and_s %>%
filter(sentiment == "negative") %>%
count(word, sort = TRUE)
sentiment_words_p_and_p %>%
ggplot() +
aes(x = sentiment) +
geom_bar()
sentiment_words_s_and_s %>%
ggplot() +
aes(x = sentiment) +
geom_bar()
library(tidyverse)
library(janeaustenr)
library(tidytext)
